## microfinance network
## data from BANERJEE, CHANDRASEKHAR, DUFLO, JACKSON 2012
## https://web.stanford.edu/~jacksonm/Banerjee-Chandrasekhar-Duflo-Jackson-DiffusionOfMicrofinance-Science-2013.pdf
library(igraph)
library(tidyverse)
## data on 8622 households
hh = read.csv("../data/microfi_households.csv", row.names="hh")
setwd("~/Dropbox/SalemCenter/classes/PRL/Spring2024/Policy-Research-Laboratory/code")
## microfinance network
## data from BANERJEE, CHANDRASEKHAR, DUFLO, JACKSON 2012
## https://web.stanford.edu/~jacksonm/Banerjee-Chandrasekhar-Duflo-Jackson-DiffusionOfMicrofinance-Science-2013.pdf
library(igraph)
library(tidyverse)
## data on 8622 households
hh = read.csv("../data/microfi_households.csv", row.names="hh")
# each row is a household
head(hh, 10)
# Let's make sure village is coded as a factor here
hh$village = factor(hh$village)
## household networks: based on survey data about household interactions
## commerce/friend/family/etc
edges = read.table("../data/microfi_edges.txt", colClasses="character")
head(edges, 10)
# pass into igraph for plotting, etc
hhnet = graph.edgelist(as.matrix(edges), directed=FALSE)
V(hhnet) ## our 8000+ household vertices
## Each vertex (node) has some attributes, and we can add more fron the hh data
# Here we'll associate a "village" attribution with each vertex
V(hhnet)$village = as.character(hh[V(hhnet),'village'])
vilcol = rainbow(nlevels(hh$village))
names(vilcol) = levels(hh$village)
V(hhnet)$color = vilcol[V(hhnet)$village]
V(hhnet)$label=NA
## we'll use induced.subgraph to select subsets of nodes and plot a couple villages
village1 = induced.subgraph(hhnet, v=which(V(hhnet)$village=="1"))
village33 = induced.subgraph(hhnet, v=which(V(hhnet)$village=="33"))
plot(village1, vertex.size=3, edge.curved=FALSE)
village33 = induced.subgraph(hhnet, v=which(V(hhnet)$village=="33"))
plot(village33, vertex.size=3, edge.curved=FALSE)
# vertex.size=3 is small.  default is 15
plot(village1, vertex.size=3, edge.curved=FALSE)
plot(village33, vertex.size=3, edge.curved=FALSE)
## The tm library and related plugins comprise R's most popular text-mining stack.
## See http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
library(tm)
library(tidyverse)
library(slam)
library(proxy)
## tm has many "reader" functions.  Each one has
## arguments elem, language, id
## (see ?readPlain, ?readPDF, ?readXML, etc)
## This wraps another function around readPlain to read
## plain text documents in English.
# I've stored this function as a Github "gist" at:
# https://gist.github.com/jgscott/28d9d1287a0c3c1477e2113f6758d5ff
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
## Test it on Adam Smith
adam = readerPlain("../data/division_of_labor.txt")
adam
meta(adam)
content(adam)
####
# Marriage and the Medici clan
####
## load the igraph package
library(igraph)
medici = as.matrix(read.table("../data/medici.txt"))
medici
marriage = graph.edgelist(medici, directed=FALSE)
V(marriage)$color = "orange"
V(marriage)["Medici"]$color = "lightblue"
V(marriage)$frame.color = 0
V(marriage)$label.color = "black"
## plot it
plot(marriage, edge.curved=FALSE)
plot(marriage, edge.curved=FALSE)
plot(marriage, edge.curved=FALSE)
plot(marriage, edge.curved=FALSE)
plot(marriage, edge.curved=FALSE)
sort(degree(marriage))
PtoA = get.shortest.paths(marriage, from="Peruzzi", to="Acciaiuoli")
allPtoA = all_shortest_paths(marriage, from="Peruzzi", to="Acciaiuoli")
allPtoA = all_shortest_paths(marriage, from="Peruzzi", to="Acciaiuoli")
allPtoA
E(marriage)$width = 2
E(marriage)$color = "grey"
E(marriage, path=PtoA$vpath[[1]])$color = "purple"
E(marriage, path=GtoS$vpath[[1]])$color = "darkgreen"
sort(round(betweenness(marriage),1))
library(tidyverse)
library(igraph)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
playlists_raw = read.csv("../data/playlists.csv")
View(playlists_raw)
str(playlists_raw)
summary(playlists_raw)
# Turn user into a factor
playlists_raw$user = factor(playlists_raw$user)
playlists = split(x=playlists_raw$artist, f=playlists_raw$user)
## Remove duplicates ("de-dupe")
playlists = lapply(playlists, unique)
playtrans = as(playlists, "transactions")
summary(playtrans)
playlists[[1]]
playlists[[2]]
length(playlists)
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=4))
inspect(musicrules)
inspect(musicrules)
inspect(musicrules)
musicrules = apriori(playtrans,
parameter=list(support=.05, confidence=.1, maxlen=4))
inspect(musicrules)
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=4))
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=4))
# Look at the output... so many rules!
inspect(musicrules)
inspect(musicrules)
?apriori
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=confidence > 0.6))
inspect(subset(musicrules, subset=lift > 10 & confidence > 0.5))
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=lift > 10 & confidence > 0.5))
plot(musicrules)
# "two key" plot: coloring is by size (order) of item set
plot(musicrules, method='two-key plot')
inspect(musicrules)
inspect(musicrules)
rm(list=ls())
library(mosaic)
##### Working with on original Levitt data
#' The response variable, Y , is per capita crime rates (violent crime, property crime, and murders) by state, from 1985 to 1997 (inclusive). The treatment variable, Z, is the “effective” abortion rate. This metric is an averaged abortion rate, weighted by criminal age at the time of arrest (to account for the fact that crimes committed by criminals should be associated with abortion rates at the time of their births).
##########################################
Original = read.table("../data/levitt_ex.dat",fill=TRUE,header=TRUE)
n=dim(Original)[1]
## Remove DC, Alaska and Hawaii
ind1 = (1:n)[Original$statenum==9]
ind2 = (1:n)[Original$statenum==2]
ind3 = (1:n)[Original$statenum==12]
ind = c(ind1,ind2,ind3)
ind1 = (1:n)[Original$year>97]
ind2 = (1:n)[Original$year<85]
ind = c(ind,ind1,ind2)
ind = unique(ind)
Data = Original[-ind,]
ind = complete.cases(Data)
Data = Data[ind,]
Data[,2] = Data[,2]-84
###
state.f = factor(Data$statenum)
states_dummies = model.matrix(~state.f)
year.f = factor(Data$year)
year_dummies = model.matrix(~year.f)
Y_M = Data$lpc_murd
D_M = Data$efamurd
Y_P = Data$lpc_prop
D_P = Data$efaprop
Y_V = Data$lpc_viol
D_V = Data$efaviol
Controls = Data[,-c(1:9)]
year = Data[,2]
head(Data)
rm(list=ls())
library(mosaic)
##### Working with on original Levitt data
#' The response variable, Y , is per capita crime rates (violent crime, property crime, and murders) by state, from 1985 to 1997 (inclusive). The treatment variable, Z, is the “effective” abortion rate. This metric is an averaged abortion rate, weighted by criminal age at the time of arrest (to account for the fact that crimes committed by criminals should be associated with abortion rates at the time of their births).
##########################################
Original = read.table("../data/levitt_ex.dat",fill=TRUE,header=TRUE)
n=dim(Original)[1]
## Remove DC, Alaska and Hawaii
ind1 = (1:n)[Original$statenum==9]
ind2 = (1:n)[Original$statenum==2]
ind3 = (1:n)[Original$statenum==12]
ind = c(ind1,ind2,ind3)
ind1 = (1:n)[Original$year>97]
ind2 = (1:n)[Original$year<85]
ind = c(ind,ind1,ind2)
ind = unique(ind)
Data = Original[-ind,]
ind = complete.cases(Data)
Data = Data[ind,]
Data[,2] = Data[,2]-84
###
state.f = factor(Data$statenum)
states_dummies = model.matrix(~state.f)
year.f = factor(Data$year)
year_dummies = model.matrix(~year.f)
Y_M = Data$lpc_murd
D_M = Data$efamurd
Y_P = Data$lpc_prop
D_P = Data$efaprop
Y_V = Data$lpc_viol
D_V = Data$efaviol
Controls = Data[,-c(1:9)]
year = Data[,2]
Interactions = Controls*as.numeric(year)
Interactions2 = Controls*(as.numeric(year)^2)
Interactions3 = states_dummies*as.numeric(year)
Interactions4 = states_dummies*as.numeric(year^2)
XO = as.matrix(cbind(Controls,states_dummies[,2:48],year_dummies[,2:13]))
XO = scale(XO)
X = as.matrix(cbind(Controls,states_dummies[,2:48],year_dummies[,2:13],Interactions,Interactions2,Interactions3[,2:48],Interactions4[,2:48]))
X = scale(X)
X = X[,-71]
# OLS confidence intervals for the causal effect (small model)
confint(lm(Y_V~D_V+XO))[2,]
confint(lm(Y_P~D_P+XO))[2,]
confint(lm(Y_M~D_M+XO))[2,]
# OLS confidence intervals for the causal effect (BIG model)
CE_V_OLS = confint(lm(Y_V~D_V+X))[2,]; CE_V_OLS
CE_P_OLS = confint(lm(Y_P~D_P+X))[2,]; CE_P_OLS
CE_M_OLS = confint(lm(Y_M~D_M+X))[2,]; CE_M_OLS
# saving OLS CI for violent crime (small model)
CE_V_OLSsmallmodel = confint(lm(Y_V~D_V+XO))[2,]
## lasso-based selection (naive - large model)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the model!
fit_reg = cv.glmnet(x=cbind(Dmod,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
hist(causal_effect)
CE_V_best = confint(causal_effect,level = 0.95)
CE_V_OLSsmallmodel
CE_V_best
CE_V_OLS
CE_V_naive
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
CE_V_naive
## lasso-based selection (naive - large model)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the model!
fit_reg = cv.glmnet(x=cbind(Dmod,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_naive = confint(causal_effect,level = 0.95)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the treatment model
fit_D = cv.glmnet(x=Xmod,y=Dmod,family="gaussian",alpha=0,nlambda=20)
Dhat = predict(fit_D,newx=Xmod,s="lambda.1se")
# fitting the outcome model
fit_reg = cv.glmnet(x=cbind(Dmod-Dhat,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_best = confint(causal_effect,level = 0.95)
CE_V_OLSsmallmodel
CE_V_best
CE_V_OLS
CE_V_naive
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
plot(xval,yval,col='white',bty='n',xlab='causal effect',main='Causal effect of abortion rate on violent crime')
legend('topleft',legend=c('OLS-small','OLS-large','Reg-naive','Reg-best'),col=c('red','blue','orange','green'),lwd=4)
abline(v=0,lty=2)
lines(xval[1:2],yval[1:2],lwd=10,col='red')
lines(xval[3:4],yval[3:4],lwd=10,col='blue')
lines(xval[5:6],yval[5:6],lwd=10,col='orange')
lines(xval[7:8],yval[7:8],lwd=10,col='green')
