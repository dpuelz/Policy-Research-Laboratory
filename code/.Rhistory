hist(causal_effect)
hist(causal_effect)
CE_V_best = confint(causal_effect,level = 0.95)
CE_V_OLSsmallmodel
CE_V_best
CE_V_OLS
CE_V_naive
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
CE_V_naive
## lasso-based selection (naive - large model)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the model!
fit_reg = cv.glmnet(x=cbind(Dmod,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_naive = confint(causal_effect,level = 0.95)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the treatment model
fit_D = cv.glmnet(x=Xmod,y=Dmod,family="gaussian",alpha=0,nlambda=20)
Dhat = predict(fit_D,newx=Xmod,s="lambda.1se")
# fitting the outcome model
fit_reg = cv.glmnet(x=cbind(Dmod-Dhat,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_best = confint(causal_effect,level = 0.95)
CE_V_OLSsmallmodel
CE_V_best
CE_V_OLS
CE_V_naive
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
plot(xval,yval,col='white',bty='n',xlab='causal effect',main='Causal effect of abortion rate on violent crime')
legend('topleft',legend=c('OLS-small','OLS-large','Reg-naive','Reg-best'),col=c('red','blue','orange','green'),lwd=4)
abline(v=0,lty=2)
lines(xval[1:2],yval[1:2],lwd=10,col='red')
lines(xval[3:4],yval[3:4],lwd=10,col='blue')
lines(xval[5:6],yval[5:6],lwd=10,col='orange')
lines(xval[7:8],yval[7:8],lwd=10,col='green')
1+1
sum(c(1,2,3,4))
class <- "PRL"
UTclass <- "PRL"
## ------------------------------------------------------------------------
5 + 3
5 - 3
5 / 3
5 ^ 3
5 * (10 - 3)
sqrt(4)
sqrt(4)
result <- 5 + 3
result
print(result)
result <- 5 - 3
result
david <- "instructor"
david
david <- "instructor and author"
david
Result <- "5"
Result
result
class(result)
class(result)
Result
class(Result)
class(sqrt)
world.pop <- c(2525779, 3026003, 3691173, 4449049, 5320817, 6127700, 6916183)
world.pop
pop.first <- c(2525779, 3026003, 3691173)
pop.second <- c(4449049, 5320817, 6127700, 6916183)
pop.all <- c(pop.first, pop.second)
pop.all
world.pop[2]
world.pop[c(2, 4)]
world.pop[c(4, 2)]
world.pop[-3]
pop.million <- world.pop / 1000
pop.million
pop.rate <- world.pop / world.pop[1]
pop.rate
pop.increase <- world.pop[-1] - world.pop[-7]
world.pop[-1]
world.pop[-7]
percent.increase <- (pop.increase / world.pop[-7]) * 100
percent.increase
plot(percent.increase)
## ------------------------------------------------------------------------
# There are many way to extract summary statistics from a given vector
length(world.pop)
min(world.pop)
max(world.pop)
range(world.pop)
mean(world.pop)
sum(world.pop) / length(world.pop)
year <- seq(from = 1950, to = 2010, by = 10)
year
year
names(world.pop)
names(world.pop) <- year
names(world.pop)
world.pop
my.summary <- function(x){ # function takes one input
s.out <- sum(x)
l.out <- length(x)
m.out <- s.out / l.out
out <- c(s.out, l.out, m.out) # define the output
names(out) <- c("sum", "length", "mean") # add labels
return(out) # end function by calling output
}
z <- 1:10
my.summary(z)
my.summary(world.pop)
my.summary(rnorm(10000))
rnorm(10000)
hist(rnorm(10000))
## ------------------------------------------------------------------------
# Let's consider an experiment where researchers have a set of resumes, and then change the names at the top to white and black sounding names.  There are 36 different names in total.  4870 total observations,
resume <- read.csv("../data/resume.csv")
View(resume)
dim(resume)
head(resume)
summary(resume)
race.call.tab <- table(race = resume$race, call = resume$call)
race.call.tab
addmargins(race.call.tab)
sum(race.call.tab[, 2]) / nrow(resume)
race.call.tab[1, 2] / sum(race.call.tab[1, ]) # black
race.call.tab[2, 2] / sum(race.call.tab[2, ]) # white
mean(resume$call) # same as line 15!
resumeBf <- subset(resume, select = c("call", "firstname"),
subset = (race == "black" & sex == "female"))
head(resumeBf)
resumeBm <- subset(resume, subset = (race == "black") & (sex == "male"))
## white female
resumeWf <- subset(resume, subset = (race == "white") & (sex == "female"))
## white male
resumeWm <- subset(resume, subset = (race == "white") & (sex == "male"))
mean(resumeWf$call) - mean(resumeBf$call) # among females
mean(resumeWm$call) - mean(resumeBm$call) # among males
(4 < 3)
crazy = (4 < 3)
"Hello" == "hello"  # R is case-sensitive
"Hello" != "hello"
x <- c(3, 2, 1, -2, -1)
c(3, 2, 1, -2, -1)
x
x >= 2
x != 1
(x > 0)
(x <= 2)
(x > 0) & (x <= 2)
(x > 2) | (x <= -1)
x.int <- (x > 0) & (x <= 2) # logical vector
x.int
(x > 0) | (x <= 2)
mean(x.int) # proportion of TRUEs
x.int
sum(x.int)  # number of TRUEs
resume$race == "black"
resume$call[resume$race == "black"]
mean(resume$call[resume$race == "black"])
resume$race[1:5]
(resume$race == "black")[1:5]
resumeB <- resume[resume$race == "black", ]
dim(resume) # dimension of original data frame
dim(resumeB) # this data.frame has fewer rows than the original data.frame
dim(resumeB) # this data.frame has fewer rows than the original data.frame
mean(resumeB$call) # callback rate for blacks
dim(resumeW) # this data.frame has fewer rows than the original data.frame
## subset whites only
resumeW <- resume[resume$race == "white", ]
dim(resumeW) # this data.frame has fewer rows than the original data.frame
mean(resumeW$call) # callback rate for blacks
resumeBf <- subset(resume, select = c("call", "firstname"),
subset = (race == "black" & sex == "female"))
head(resumeBf)
resumeBm <- subset(resume, subset = (race == "black") & (sex == "male"))
## white female
resumeWf <- subset(resume, subset = (race == "white") & (sex == "female"))
## white male
resumeWm <- subset(resume, subset = (race == "white") & (sex == "male"))
mean(resumeWf$call) - mean(resumeBf$call) # among females
mean(resumeWm$call) - mean(resumeBm$call) # among males
resume$BlackFemale <- ifelse(resume$race == "black" &
resume$sex == "female", 1, 0)
View(resume)
setwd("~/Downloads")
survery = read.csv("survey.csv")
survey = read.csv("survey.csv")
summary(survey)
summary(survey)
survey = read.csv("survey.csv")
summary(survey)
survey$year==1951
mean(survey$ideology[survey$year==1950])
mean(survey$ideology[survey$year==1950],na.rm=TRUE)
unique(survey$year)
mean(survey$ideology[survey$year==1950],na.rm=TRUE)
mean(survey$ideology[survey$year==1951],na.rm=TRUE)
mean(survey$ideology[survey$year==1952],na.rm=TRUE)
survey_y <- survey %>%
filter(draft==1) %>%
summarize(mean_ideology=mean(ideology))
# draft lottery
library(tidyverse)
# draft lottery
library(tidyverse)
survey_y <- survey %>%
filter(draft==1) %>%
summarize(mean_ideology=mean(ideology))
survey_n <- survey %>%
filter(draft==0) %>%
summarize(mean_ideology=mean(ideology))
survey_y
survey_n
survey_y <- survey %>%
filter(draft==1) %>%
summarize(mean_ideology=mean(ideology,na.rm=T))
survey_n <- survey %>%
filter(draft==0) %>%
summarize(mean_ideology=mean(ideology,na.rm=T))
survey_y
survey_n
survey_y - survey_n
survey_y - survey_n
mean(survey$ideology[survey$draft==1],na.rm=TRUE)-
mean(survey$ideology[survey$draft==0],na.rm=TRUE)
unique(survey$state)
mean(survey$ideology[survey$draft==1 & survey$state=="CO"],na.rm=TRUE)-
mean(survey$ideology[survey$draft==0 & survey$state=="CO"],na.rm=TRUE)
mean(survey$ideology[survey$draft==1 & survey$state=="OR"],na.rm=TRUE)-
mean(survey$ideology[survey$draft==0 & survey$state=="OR"],na.rm=TRUE)
#' In this script, we investigate a policing experiment and see how to use the
#' FRT to characterize statistical uncertainty in the DiM estimator of the SATE
# First, load in all of the data
load('../data/Z_police.RData') # treatment assignments
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2024/Policy-Research-Laboratory/code")
#' In this script, we investigate a policing experiment and see how to use the
#' FRT to characterize statistical uncertainty in the DiM estimator of the SATE
# First, load in all of the data
load('../data/Z_police.RData') # treatment assignments
load('../data/network_police.RData') # network
load('../data/outcomes_police.RData') # outcomes of interest
#' In this script, we investigate a policing experiment and see how to use the
#' FRT to characterize statistical uncertainty in the DiM estimator of the SATE
# First, load in all of the data
load('../data/Z_police.RData') # treatment assignments
load('../data/network_police.RData') # network
load('../data/outcomes_police.RData') # outcomes of interest
# convert to data frames and reorder rows
network = as.data.frame(network)
network = network[order(as.numeric(rownames(network))),]
outcomes = as.data.frame(outcomes)
outcomes = outcomes[order(as.numeric(rownames(outcomes))),]
Z = as.data.frame(Z)
# Let's plot our data first, what are we looking at?
head(network)
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
head(outcomes)
Y = (outcomes$hmotos +  outcomes$hcarros)*0.221 +
outcomes$homicidio*0.550 + outcomes$lesiones*0.112 +
outcomes$hpersonas*0.116
names(Y) = rownames(outcomes)
points(network,col=rgb(1,0,0,alpha=0.5),cex=1.75*Y,pch=19)
# Let's plot the observed treatment
dim(Z)
Zobs = Z[,1]; names(Zobs) = rownames(Z)
Zobs_long = rep(0,nrow(network)) # need to make a long Z
hotspot_indices = match(names(Zobs),rownames(network)) # indices in network dataframe that correspond to hotspot indices
Zobs_long[hotspot_indices] <- Zobs
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
points(network[hotspot_indices,],col='blue',pch=19,cex=0.6)
points(network[which(Zobs_long==1),],col='green',pch=8,cex=0.75)
treatmentlong = function(Zalt,network,hotspot_indices){
Zalt
Zalt_long = rep(0,nrow(network))
Zalt_long[hotspot_indices] <- Zalt
return(Zalt_long)
}
# A second function that uses the one above for plotting
plottreatment = function(Zalt,network,hotspot_indices){
Zalt_long = treatmentlong(Zalt,network,hotspot_indices)
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
points(network[hotspot_indices,],col='blue',pch=19,cex=0.6)
points(network[which(Zalt_long==1),],col='green',pch=8,cex=0.75)
}
# A second function that uses the one above for plotting
plottreatment = function(Zalt,network,hotspot_indices){
Zalt_long = treatmentlong(Zalt,network,hotspot_indices)
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
points(network[hotspot_indices,],col='blue',pch=19,cex=0.6)
points(network[which(Zalt_long==1),],col='green',pch=8,cex=0.75)
}
dim(Z)
plottreatment(Z[,1],network,hotspot_indices)
plottreatment(Z[,2],network,hotspot_indices)
plottreatment(Z[,3],network,hotspot_indices)
plottreatment(Z[,4],network,hotspot_indices)
plottreatment(Z[,5],network,hotspot_indices)
plottreatment(Z[,2],network,hotspot_indices)
plottreatment(Z[,3],network,hotspot_indices)
plottreatment(Z[,4],network,hotspot_indices)
plottreatment(Z[,5],network,hotspot_indices)
plottreatment(Z[,10000],network,hotspot_indices)
Yobs = Y[hotspot_indices]
DiM = mean(Yobs[which(Zobs==1)]) - mean(Yobs[which(Zobs==0)])
DiM = mean(Yobs[which(Zobs==1)]) - mean(Yobs[which(Zobs==0)])
DiM
DiM_function = function(Zalt,Y){
DiM = mean(Y[which(Zalt==1)]) - mean(Y[which(Zalt==0)])
return(DiM)
}
DiM_observed = DiM_function(Z[,1],Yobs)
DiM_observed
ncol(Z[,-1]))
ncol(Z[,-1])
for(i in 1:ncol(Z[,-1])){
DiM_alt = c(DiM_alt,DiM_function(Z[,i+1],Yobs))
}
DiM_alt = c()
for(i in 1:ncol(Z[,-1])){
DiM_alt = c(DiM_alt,DiM_function(Z[,i+1],Yobs))
}
DiM_alt
hist(DiM_alt)
DiM_alt = apply(Z[,-1],MARGIN=2,DiM_function,Y=Yobs)
apply(Z,2,mean)
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
2^30
2^967
Yobs = outcomes$homicidio[hotspot_indices]
Yobs = outcomes$homicidio[hotspot_indices]
Yobs
DiM_alt = apply(Z[,-1],2,DiM_function,Y=Yobs)
DiM_observed = DiM_function(Z[,1],Yobs)
DiM_observed
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
Yobs = outcomes$hcarros[hotspot_indices]
DiM_alt = apply(Z[,-1],2,DiM_function,Y=Yobs)
DiM_observed = DiM_function(Z[,1],Yobs)
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
## ------------------------------------------------------------------------
minwage <- read.csv("../data/minwage.csv") # load the data
minwage
colnames(minwage)
## ------------------------------------------------------------------------
minwage <- read.csv("../data/minwage.csv") # load the data
dim(minwage)
summary(minwage)
minwageNJ <- subset(minwage, subset = (location != "PA"))
minwagePA <- subset(minwage, subset = (location == "PA"))
mean(minwageNJ$wageBefore < 5.05)
mean(minwageNJ$wageAfter < 5.05)
mean(minwagePA$wageBefore < 5.05)
mean(minwagePA$wageAfter < 5.05)
minwageNJ$fullPropAfter <- minwageNJ$fullAfter /
(minwageNJ$fullAfter + minwageNJ$partAfter)
minwagePA$fullPropAfter <- minwagePA$fullAfter /
(minwagePA$fullAfter + minwagePA$partAfter)
mean(minwageNJ$fullPropAfter) - mean(minwagePA$fullPropAfter)
prop.table(table(minwageNJ$chain))
prop.table(table(minwagePA$chain))
minwageNJ.bk <- subset(minwageNJ, subset = (chain == "burgerking"))
minwagePA.bk <- subset(minwagePA, subset = (chain == "burgerking"))
mean(minwageNJ.bk$fullPropAfter) - mean(minwagePA.bk$fullPropAfter)
dim(minwage)
summary(minwage)
minwageNJ <- subset(minwage, subset = (location != "PA"))
minwagePA <- subset(minwage, subset = (location == "PA"))
minwageNJ$wageBefore < 5.05
mean(minwageNJ$wageBefore < 5.05)
mean(minwageNJ$wageAfter < 5.05)
mean(minwagePA$wageBefore < 5.05)
mean(minwagePA$wageAfter < 5.05)
minwageNJ$fullPropAfter <- minwageNJ$fullAfter /
(minwageNJ$fullAfter + minwageNJ$partAfter)
minwagePA$fullPropAfter <- minwagePA$fullAfter /
(minwagePA$fullAfter + minwagePA$partAfter)
minwageNJ$fullPropAfter
hist(minwageNJ$fullPropAfter)
mean(minwageNJ$fullPropAfter) - mean(minwagePA$fullPropAfter)
prop.table(table(minwageNJ$chain))
prop.table(table(minwagePA$chain))
sum(prop.table(table(minwageNJ$chain)))
prop.table(table(minwageNJ$chain))
?prop.table
sum(prop.table(table(minwageNJ$chain)))
prop.table(table(minwageNJ$chain))
prop.table(table(minwagePA$chain))
minwageNJ.bk <- subset(minwageNJ, subset = (chain == "burgerking"))
minwagePA.bk <- subset(minwagePA, subset = (chain == "burgerking"))
mean(minwageNJ.bk$fullPropAfter) - mean(minwagePA.bk$fullPropAfter)
mean(minwageNJ.bk$fullPropAfter) - mean(minwagePA.bk$fullPropAfter)
minwageNJ.bk.subset <-
subset(minwageNJ.bk, subset = ((location != "shoreNJ") &
(location != "centralNJ")))
mean(minwageNJ.bk.subset$fullPropAfter) - mean(minwagePA.bk$fullPropAfter)
source("~/Dropbox/SalemCenter/classes/PRL/Fall2024/Policy-Research-Laboratory/code/causality_minwage.R", echo=TRUE)
minwageNJ.bk.subset
dim(minwageNJ$fullPropAfter)
length(minwageNJ$fullPropAfter)
minwageNJ.bk.subset <-
subset(minwageNJ.bk, subset = ((location != "shoreNJ") &
(location != "centralNJ")))
dim(minwageNJ.bk.subset)
mean(minwageNJ.bk.subset$fullPropAfter) - mean(minwagePA.bk$fullPropAfter)
minwageNJ$fullPropBefore <- minwageNJ$fullBefore /
(minwageNJ$fullBefore + minwageNJ$partBefore)
NJdiff <- mean(minwageNJ$fullPropAfter) - mean(minwageNJ$fullPropBefore)
NJdiff
minwagePA$fullPropBefore <- minwagePA$fullBefore /
(minwagePA$fullBefore + minwagePA$partBefore)
PAdiff <- mean(minwagePA$fullPropAfter) - mean(minwagePA$fullPropBefore)
PAdiff
NJdiff - PAdiff
# Example 1: binomial for airline no shows
# Parameters
P = 0.09
N = 140
# Create a grid of k's
k_grid = seq(0, 30, by=1)
k_grid
dbinom(k_grid, N, P)
barplot(dbinom(k_grid, N, P), names.arg = k_grid,
xlab='Number of no shows',
ylab='Probability')
sum(dbinom(0:5, N, P))
sum(dbinom(12:140, N, P)) # this is the answer to our question on the slides!
dbinom(12:140, N, P)
sum(dbinom(12:140, N, P)) # this is the answer to our question on the slides!
1 - pbinom(11, size=N, prob=P)
?pbinom
x_grid = 0:7
dpois(x_grid, 1.6)
barplot(dpois(x_grid, 1.6), names.arg = x_grid,
cex.names=1.1, las=1, ylim=c(0,0.35),
xlab='Goals',
ylab='Probability', main="UT: Poisson(1.6)")
barplot(dpois(x_grid, 1.3), names.arg = x_grid,
cex.names=1.1, las=1, ylim=c(0,0.35),
xlab='Goals',
ylab='Probability', main="Texas Tech: Poisson(1.3)")
NMC = 100000
UT = rpois(NMC, 1.6)
Tech = rpois(NMC, 1.3)
UT
xtabs(~UT + Tech)
results_table = xtabs(~UT + Tech)/NMC
round(results_table,2)
sum(UT > Tech)/NMC
sum(UT == Tech)/NMC
sum(UT < Tech)/NMC
dpois(1, 1.6) * dpois(1, 1.3) # UT 1 - 1 Texas Tech
dpois(2, 1.6) * dpois(0, 1.3) # UT 2 - 0 Texas Tech
round(results_table,2)
# A cool figure for those who want to geek out with R graphics
my_cols = grey(seq(1, 0.5, length=15))
my_breaks = seq(0, 0.12, length=16)
image(0:5, 0:5, results_table[1:5,1:5],
xlim=c(-0.5, 5.5),
ylim=c(-0.5, 5.5),
col=my_cols, breaks=my_breaks,
las=1, bty='n',
main="Probability of outcomes for the \nUT vs. Texas Tech match",
ylab='Texas Tech goals',
xlab="UT goals")
abline(h=-0.5 + 0:6, lty='dotted')
abline(v=-0.5 + 0:6, lty='dotted')
for(i in 1:6) {
for(j in 1:6) {
text(i-1, j-1, results_table[i,j])
if(i > j) {
rect(i-1.5,j-1.5,i-0.5, j-0.5, border='blue', lwd=2)
}
}
}
hist(rnorm(1000,mean=0,sd=1),col='gray',freq = FALSE)
hist(rnorm(100000,mean=0,sd=1),col='gray',freq = FALSE,breaks=100)
K = 3
pnorm(3,mean=0,sd=1) # cumulative density function, calculate P(x<=K) for one value of K
ii = seq(-3,3,length.out=1000)
plot(ii,pnorm(ii,mean=0,sd=1),type='l',xlab='')
par(mfrow=c(1,2))
hist(rnorm(10000,mean=0,sd=1),col='gray',freq = FALSE,xlab='',main='PDF of Normal')
plot(ii,pnorm(ii,mean=0,sd=1),type='l',xlab='',main='CDF of Normal')
