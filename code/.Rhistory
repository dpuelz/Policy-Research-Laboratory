boot1
KHOU_squared = load_combined$KHOU^2
load_combined$KHOU_squared = KHOU_squared
numboot = 200
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined)))
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
load_combined_small = sample(load_combined,50)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
# smaller sample
load_combined_small = sample(load_combined,20)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
# smaller sample
load_combined_small = sample(load_combined,100)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
# smaller sample
load_combined_small = sample(load_combined,1000)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
head(load_combined)
dim(load_combined)
write.csv(load_combined,file="ercot.csv")
write.csv(load_combined_small,file="ercot.csv")
# Simple linear regression
lm1 = lm(COAST ~ KHOU, data=load_combined)
summary(lm1)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
abline(lm1,lty=1,lwd=4,col='blue')
dev.off()
plot(creatclear~age, data=creatinine,
pch=19, col='grey', bty='n',
ylab="creatinine score", xlab="Age")
lm1 = lm(creatclear~age, data=creatinine)
abline(lm1, lwd=2, col='blue')
coef(lm1)
# Bootstrap
boot1 = do(1000000)*lm(creatclear~age, data=resample(creatinine))
KHOU_squared = load_combined$KHOU^2
load_combined$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined)))
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
x = load_combined$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature",ylab="power demand")
data = read.csv('../data/housedata.csv')
fit = lm(Price~Size,data)
plot(data)
fit = lm(Price~Size,data)
summary(fit)
## Bootstrapping example
library(mosaic)
creatinine = read.csv("../data/creatinine.csv", header=TRUE)
head(creatinine)
### Bootstrapping the sample mean
# Look at the mean creatinine clearance rate
mean(creatinine$creatclear)
# OK, 125.25 +/- what?
# Bootstrap to get a standard error
boot1 = do(100)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
n = nrow(creatclear)
creatclear
n = nrow(creatinine)
se_closedform = sqrt(s^2/n)
# formula for standard error? se = sqrt(s^2/n)
s = sd(creatinine$creatclear)
n = nrow(creatinine)
se_closedform = sqrt(s^2/n)
boot1 = do(10000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
# formula for standard error? se = sqrt(s^2/n)
s = sd(creatinine$creatclear)
n = nrow(creatinine)
se_closedform = sqrt(s^2/n)
se_closedform
boot1 = do(100000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
se_closedform
boot1 = do(500)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
s = sd(creatinine$creatclear)
n = nrow(creatinine)
se_closedform = sqrt(s^2/n)
se_closedform
# Bootstrap to get a standard error
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
library(lubridate)
library(tidyverse)
# example 1: of simple linear regression
data = read.csv('../data/housedata.csv')
fit = lm(Price~Size,data)
summary(fit)
# example 2: ERCOT
# Power grid load every hour for 6 1/2 years
# throughout the 8 ERCOT regions of Texas
# units of grid load are megawatts.
# This represents peak instantaneous demand for power in that hour.
# source: scraped from the ERCOT website
load_ercot = read.csv("../data/load_ercot.csv")
# Now weather data at the KHOU weather station
# temps in F
load_temperature = read.csv("../data/load_temperature.csv")
# Merge the two data sets on their common field: Time
# Now we'll have access to the temperature data to predict power consumption
load_combined = merge(load_ercot, load_temperature, by = 'Time')
head(load_combined)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
# first things first: let's get the Time variable into a format R understands.
# Right now R thinks it's just a string of characters.
# We need to tell R it's actually a time stamp in a specific format: Y-M-D H:M:S
# We'll do this with the ymd_hms function in the lubridate package
load_combined = mutate(load_combined,
Time = ymd_hms(Time))
plot(load_combined$Time,load_combined$COAST,type='l',col=rgb(0,0,0,alpha=0.6))
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
# Simple linear regression
lm1 = lm(COAST ~ KHOU, data=load_combined)
summary(lm1)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
abline(lm1,lty=1,lwd=4,col='blue')
# What about an additional variable?
KHOU_squared = load_combined$KHOU^2
load_combined$KHOU_squared = KHOU_squared
lm2 = lm(COAST ~ KHOU + KHOU_squared, data=load_combined)
summary(lm2)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = lm2$coefficients[1] + lm2$coefficients[2]*xnew + lm2$coefficients[3]*xnew^2
lines(xnew,quadfit,col=2,lwd=3)
dev.off()
# Look at the mean creatinine clearance rate
mean(creatinine$creatclear)
View(creatinine)
## Bootstrapping example
library(mosaic)
creatinine = read.csv("../data/creatinine.csv", header=TRUE)
head(creatinine)
1+1
mean(creatinine$creatclear)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
s = sd(creatinine$creatclear)
n = nrow(creatinine)
n
s
se_closedform = sqrt(s^2/n)
se_closedform
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
boot1 = do(5000)*{
mean(resample(creatinine)$creatclear)
}
hist(boot1$result)
sd(boot1$result)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
KHOU_squared = load_combined$KHOU^2
load_combined$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined)))
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
# smaller sample
load_combined_small = sample(load_combined,1000)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
# smaller sample
load_combined_small = sample(load_combined,100)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
load_combined_small = sample(load_combined,50)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
load_combined_small = sample(load_combined,15)
KHOU_squared = load_combined_small$KHOU^2
load_combined_small$KHOU_squared = KHOU_squared
numboot = 200
lm2 = do(numboot)*(lm(COAST ~ KHOU + KHOU_squared, data=resample(load_combined_small)))
plot(load_combined_small$KHOU,load_combined_small$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8,xlab="temperature (F)",ylab="power demand")
x = load_combined_small$KHOU
xmin = floor(min(x))
xmax = floor(max(x))
xnew = seq(xmin,xmax,length.out=500)
quadfit = array(NA,c(numboot,length(xnew)))
for(ii in 1:numboot){
quadfit[ii,] = lm2$Intercept[ii] + lm2$KHOU[ii]*xnew +   lm2$KHOU_squared[ii]*xnew^2
lines(xnew,quadfit[ii,],col=rgb(1,0,0,alpha=0.3),lwd=1)
}
setwd("~/Dropbox/Charles/HeartData")
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
library(plotmo)
library(ggplot2)
# naming function
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
newgsub(colnames(variable),newvarname)
}
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
dim(DF)
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
library(plotmo)
library(ggplot2)
# naming function
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
newgsub(colnames(variable),newvarname)
}
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
# making new outcome
## combine Ischemic.symptoms with "preop variables"
## single binary if any are 1, 0 otherwise.
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
# removing variables with no variation
iremove = which(sapply((lapply(DF,unique)),length)==1)
DF=DF[,-iremove]
gender = one_hot(as.data.table(DF$Gender))[,2]
colnames(gender)=namefun(gender,"gender")
race = one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
colnames(race)=namefun(race,"race")
imlength = as.numeric(DF$IM.length)
imlength[is.na(imlength)] = 0
cordom = one_hot(as.data.table(DF$Coroanry.dominance))[,-1]
colnames(cordom)=namefun(cordom,"cordom")
ostium = one_hot(as.data.table(DF$Stenotic.ostium))[,-1]
colnames(ostium)=namefun(ostium,"ostium")
# combine elliptical and oval, combine round and Round
DF$round.oval.slit.like[which(DF$round.oval.slit.like=="Round")] <- "round"
DF$round.oval.slit.like[which(DF$round.oval.slit.like=="elliptical")] <- "oval"
geometry = one_hot(as.data.table(DF$round.oval.slit.like))[,-1]
colnames(geometry)=namefun(geometry,"geometry")
intramurality = one_hot(as.data.table(DF$Intramurality))[,-1]
colnames(intramurality)=namefun(intramurality,"intramurality")
acuteangulation = one_hot(as.data.table(DF$Acute.angulation.))[,-1]
colnames(acuteangulation)=namefun(acuteangulation,"acuteangulation")
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
X = as.matrix(cbind(race,gender,imlength,cordom,ostium,geometry,intramurality,acuteangulation))
iremove = which(colSums(X)==0)
X = X[,-iremove]
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
fit = cv.glmnet(x=X,y=Y,family="binomial",alpha=0)
lambda_opt = fit$lambda.min
fit_opt_allpath = glmnet(x=X,y=Y,family="binomial",alpha=1)
fit_opt = glmnet(x=X,y=Y,family="binomial",alpha=1,lambda=lambda_opt)
dim(fit_opt$beta)
ismall = which(minOOS_model!=0)
minOOS_model = fit_opt$beta
ismall = which(minOOS_model!=0)
ismall
# define a smaller set of variables
Xsmall = X[,ismall]
fitlogit = glm(Y~Xsmall,family = "binomial")
summary(fitlogit)
library(mosaic)
## load the data and subset them into two parties
MPs <- read.csv("../data/MPs.csv")
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2023/Policy-Research-Laboratory/code")
library(mosaic)
## load the data and subset them into two parties
MPs <- read.csv("../data/MPs.csv")
MPs.labour <- subset(MPs, subset = (party == "labour"))
MPs.tory <- subset(MPs, subset = (party == "tory"))
head(MPs)
## two regressions for Labour: negative and positive margin
labour.fit1 <- lm(ln.net ~ margin,
data = MPs.labour[MPs.labour$margin < 0, ])
labour.fit2 <- lm(ln.net ~ margin,
data = MPs.labour[MPs.labour$margin > 0, ])
## two regressions for Tory: negative and positive margin
tory.fit1 <- lm(ln.net ~ margin, data = MPs.tory[MPs.tory$margin < 0, ])
tory.fit2 <- lm(ln.net ~ margin, data = MPs.tory[MPs.tory$margin > 0, ])
## Labour: range of predictions
y1l.range <- c(min(MPs.labour$margin), 0) # min to 0
y2l.range <- c(0, max(MPs.labour$margin)) # 0 to max
## prediction
y1.labour <- predict(labour.fit1, newdata = data.frame(margin = y1l.range))
y2.labour <- predict(labour.fit2, newdata = data.frame(margin = y2l.range))
## Tory: range of predictions
y1t.range <- c(min(MPs.tory$margin), 0) # min to 0
y2t.range <- c(0, max(MPs.tory$margin)) # 0 to max
## predict outcome
y1.tory <- predict(tory.fit1, newdata = data.frame(margin = y1t.range))
y2.tory <- predict(tory.fit2, newdata = data.frame(margin = y2t.range))
## scatterplot with regression lines for labour
plot(MPs.labour$margin, MPs.labour$ln.net, main = "Labour",
xlim = c(-0.5, 0.5), ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death",pch=19,col='gray')
abline(v = 0, lty = "dashed")
## add regression lines
lines(y1l.range, y1.labour, col = "blue",lwd=2)
lines(y2l.range, y2.labour, col = "blue",lwd=2)
library(lubridate)
library(tidyverse)
# example 1: of simple linear regression
data = read.csv('../data/housedata.csv')
fit = lm(Price~Size,data)
summary(fit)
# example 2: ERCOT
# Power grid load every hour for 6 1/2 years
# throughout the 8 ERCOT regions of Texas
# units of grid load are megawatts.
# This represents peak instantaneous demand for power in that hour.
# source: scraped from the ERCOT website
load_ercot = read.csv("../data/load_ercot.csv")
# Now weather data at the KHOU weather station
# temps in F
load_temperature = read.csv("../data/load_temperature.csv")
# Merge the two data sets on their common field: Time
# Now we'll have access to the temperature data to predict power consumption
load_combined = merge(load_ercot, load_temperature, by = 'Time')
head(load_combined)
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
# first things first: let's get the Time variable into a format R understands.
# Right now R thinks it's just a string of characters.
# We need to tell R it's actually a time stamp in a specific format: Y-M-D H:M:S
# We'll do this with the ymd_hms function in the lubridate package
load_combined = mutate(load_combined,
Time = ymd_hms(Time))
plot(load_combined$Time,load_combined$COAST,type='l',col=rgb(0,0,0,alpha=0.6))
plot(load_combined$KHOU,load_combined$COAST,col=rgb(0,0,0,alpha=0.1),pch=19,cex=0.8)
# Simple linear regression
lm1 = lm(COAST ~ KHOU, data=load_combined)
summary(lm1)
plot(lm1)
rm(list=ls())
