U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
install.packages("devtools")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(BicliqueRT)
hello
blah
install.packages("swirl")
library(swirl)
install_course_github("kosukeimai","qss-swirl")
library()
swirl()
install_course("qss-swirl")
install_course("qss-swirl")
install_course("qss-swirl")
library(swirl) # load the swirl package
install_course_github("kosukeimai", "qss-swirl")
swirl()
8-2
10^2
sqrt(9)
remotes::install_github("kosukeimai/qss-package", build_vignettes = TRUE)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
##
test <- function(seed){
res <- seed + seed
res
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
x=c(1,2,3,4)
y=c(1,2,3,4)
table(x~y)
table(x)
summary(table)
as.table(x,y)
?Summarize
load('Downloads/tobs_debug.rds')
readRDS('Downloads/tobs_debug.rds')
readRDS('Downloads/tval_debug.rds')
readRDS('Downloads/pvalue_debug.rds')
## ------------------------------------------------------------------------
# Let's consider an experiment where researchers have a set of resumes, and then change the names at the top to white and black sounding names.  There are 36 different names in total.  4870 total observations,
resume <- read.csv("../data/resume.csv")
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2022/Policy-Research-Laboratory/code")
## ------------------------------------------------------------------------
# Let's consider an experiment where researchers have a set of resumes, and then change the names at the top to white and black sounding names.  There are 36 different names in total.  4870 total observations,
resume <- read.csv("../data/resume.csv")
dim(resume)
head(resume)
summary(resume)
## ------------------------------------------------------------------------
# Let's consider an experiment where researchers have a set of resumes, and then change the names at the top to white and black sounding names.  There are 36 different names in total.  4870 total observations,
resume <- read.csv("../data/resume.csv")
dim(resume)
head(resume)
summary(resume)
race.call.tab <- table(race = resume$race, call = resume$call)
race.call.tab
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2022/Policy-Research-Laboratory/code")
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2022/Policy-Research-Laboratory/code")
resume <- read.csv("../data/resume.csv")
resume <- read.csv("../data/resume.csv")
dim(resume)
head(resume)
summary(resume)
race.call.tab <- table(race = resume$race, call = resume$call)
race.call.tab
addmargins(race.call.tab)
sum(race.call.tab[, 2]) / nrow(resume)
dim(resume)[1]
race.call.tab[, 2]
sum(race.call.tab[, 2]) / nrow(resume)
race.call.tab[1, 2]
race.call.tab
race.call.tab[1, ]
sum(race.call.tab[1, ])
race.call.tab[1, 2]
race.call.tab[1, 2] / sum(race.call.tab[1, ]) # black
race.call.tab[2, 2] / sum(race.call.tab[2, ]) # white
race.call.tab[1, ]  # the first row
race.call.tab[ , 2]  # the second column
race.call.tab[,2]  # the second column
mean(resume$call) # same as line 15!
class(TRUE)
as.integer(TRUE)
as.integer(FALSE)
x <- c(TRUE, FALSE, TRUE) # a vector with logical values
x
mean(x)
sum(x) # number of TRUEs
FALSE & TRUE
TRUE & TRUE
TRUE | FALSE
FALSE | FALSE
TRUE & FALSE & TRUE
TF1 <- c(TRUE, FALSE, FALSE)
TF2 <- c(TRUE, FALSE, TRUE)
TF1
TF2
TF1 | TF2
4 < 3
"Hello" == "hello"  # R is case-sensitive
"Hello" != "hello"
charles = 'student'
charles <- 'student'
charles <- 'beststudent'
1:100
test = 1:100
test
testsq = test^2
testsq
plot(testsq)
resume$race
resume$race == "black"
resume$call[resume$race == "black"]
mean(resume$call[resume$race == "black"])
resume$race[1:5]
(resume$race == "black")[1:5]
resumeB <- resume[resume$race == "black", ]
dim(resumeB)
mean(resumeB$call) # callback rate for blacks
resumeW <- resume[resume$race == "white", ]
dim(resumeW) # this data.frame has fewer rows than the original
mean(resumeW$call)
resumeBf <- subset(resume, select = c("call", "firstname"),
subset = (race == "black" & sex == "female"))
head(resumeBf)
dim(resumeBf)
resumeBm <- subset(resume, subset = (race == "black") & (sex == "male"))
resumeWf <- subset(resume, subset = (race == "white") & (sex == "female"))
resumeWm <- subset(resume, subset = (race == "white") & (sex == "male"))
mean(resumeWf$call) - mean(resumeBf$call) # among females
mean(resumeWm$call) - mean(resumeBm$call) # among males
heaD(resume)
head(resume)
#' In this script, we investigate a policing experiment and see how to use the
#' FRT to characterize statistical uncertainty in the DiM estimator of the SATE
# First, load in all of the data
load('../data/Z_police.RData') # treatment assignments
load('../data/network_police.RData') # network
load('../data/outcomes_police.RData') # outcomes of interest
# convert to data frames and reorder rows
network = as.data.frame(network)
dim(network)
head(network)
# convert to data frames and reorder rows
network = as.data.frame(network)
network = network[order(as.numeric(rownames(network))),]
outcomes = as.data.frame(outcomes)
outcomes = outcomes[order(as.numeric(rownames(outcomes))),]
head(outcomes)
head(network)
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
head(outcomes)
Y = (outcomes$hmotos +  outcomes$hcarros)*0.221 +
outcomes$homicidio*0.550 + outcomes$lesiones*0.112 +
outcomes$hpersonas*0.116
names(Y) = rownames(outcomes)
points(network,col=rgb(1,0,0,alpha=0.5),cex=Y,pch=19)
dim(Z)
Zobs = Z[,1]; names(Zobs) = rownames(Z)
Zobs_long = rep(0,nrow(network)) # need to make a long Z
hotspot_indices = match(names(Zobs),rownames(network)) # indices in network dataframe that correspond to hotspot indices
Zobs_long[hotspot_indices] <- Zobs
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
points(network[hotspot_indices,],col='blue',pch=19,cex=0.6)
points(network[which(Zobs_long==1),],col='green',pch=8,cex=0.75)
treatmentlong = function(Zalt,network,hotspot_indices){
Zalt
Zalt_long = rep(0,nrow(network))
Zalt_long[hotspot_indices] <- Zalt
return(Zalt_long)
}
# A second function that uses the one above for plotting
plottreatment = function(Zalt,network,hotspot_indices){
Zalt_long = treatmentlong(Zalt,network,hotspot_indices)
plot(network,xlab='',ylab='',pch=19,cex=0.4,col=rgb(0.5,0.5,0.5,alpha=0.5),xaxt='n',yaxt='n',bty='n')
points(network[hotspot_indices,],col='blue',pch=19,cex=0.6)
points(network[which(Zalt_long==1),],col='green',pch=8,cex=0.75)
}
# bringing it all together
plottreatment(Z[,1],network,hotspot_indices)
plottreatment(Z[,2],network,hotspot_indices)
plottreatment(Z[,3],network,hotspot_indices)
plottreatment(Z[,4],network,hotspot_indices)
plottreatment(Z[,5],network,hotspot_indices)
Yobs = Y[hotspot_indices]
DiM = mean(Yobs[which(Zobs==1)]) - mean(Yobs[which(Zobs==0)])
DiM
DiM_function = function(Zalt,Y){
DiM = mean(Y[which(Zalt==1)]) - mean(Y[which(Zalt==0)])
return(DiM)
}
DiM_observed = DiM_function(Z[,1],Yobs)
DiM_observed
# calculate alternative DiM's in a for loop
DiM_alt = c()
for(i in 1:ncol(Z[,-1])){
DiM_alt = c(DiM_alt,DiM_function(Z[,i+1],Yobs))
}
DiM_alt = apply(Z[,-1],MARGIN=2,DiM_function,Y=Yobs)
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
# homicides
Yobs = outcomes$homicidio[hotspot_indices]
DiM_alt = apply(Z[,-1],2,DiM_function,Y=Yobs)
DiM_observed = DiM_function(Z[,1],Yobs)
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
# car jackings
Yobs = outcomes$hcarros[hotspot_indices]
DiM_alt = apply(Z[,-1],2,DiM_function,Y=Yobs)
DiM_observed = DiM_function(Z[,1],Yobs)
hist(DiM_alt)
abline(v=DiM_observed,col='blue',lwd=3)
p = mean(DiM_alt<DiM_observed)
min(p,1-p)
