CE_V_best
CE_V_OLS
CE_V_naive
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
plot(xval,yval,col='white',bty='n',xlab='causal effect',main='Causal effect of abortion rate on violent crime')
legend('topleft',legend=c('OLS-small','OLS-large','Reg-naive','Reg-best'),col=c('red','blue','orange','green'),lwd=4)
abline(v=0,lty=2)
lines(xval[1:2],yval[1:2],lwd=10,col='red')
lines(xval[3:4],yval[3:4],lwd=10,col='blue')
lines(xval[5:6],yval[5:6],lwd=10,col='orange')
lines(xval[7:8],yval[7:8],lwd=10,col='green')
dev.off()
rm(list=ls())
library(mosaic)
##### Working with on original Levitt data
#' The response variable, Y , is per capita crime rates (violent crime, property crime, and murders) by state, from 1985 to 1997 (inclusive). The treatment variable, Z, is the “effective” abortion rate. This metric is an averaged abortion rate, weighted by criminal age at the time of arrest (to account for the fact that crimes committed by criminals should be associated with abortion rates at the time of their births).
##########################################
Original = read.table("../data/levitt_ex.dat",fill=TRUE,header=TRUE)
n=dim(Original)[1]
## Remove DC, Alaska and Hawaii
ind1 = (1:n)[Original$statenum==9]
ind2 = (1:n)[Original$statenum==2]
ind3 = (1:n)[Original$statenum==12]
ind = c(ind1,ind2,ind3)
ind1 = (1:n)[Original$year>97]
ind2 = (1:n)[Original$year<85]
ind = c(ind,ind1,ind2)
ind = unique(ind)
Data = Original[-ind,]
ind = complete.cases(Data)
Data = Data[ind,]
Data[,2] = Data[,2]-84
state.f = factor(Data$statenum)
states_dummies = model.matrix(~state.f)
year.f = factor(Data$year)
year_dummies = model.matrix(~year.f)
Y_M = Data$lpc_murd
D_M = Data$efamurd
Y_P = Data$lpc_prop
D_P = Data$efaprop
Y_V = Data$lpc_viol
D_V = Data$efaviol
Controls = Data[,-c(1:9)]
Controls
Interactions = Controls*as.numeric(year)
year = Data[,2]
Interactions = Controls*as.numeric(year)
Interactions2 = Controls*(as.numeric(year)^2)
Interactions3 = states_dummies*as.numeric(year)
Interactions4 = states_dummies*as.numeric(year^2)
XO = as.matrix(cbind(Controls,states_dummies[,2:48],year_dummies[,2:13]))
XO = scale(XO)
X = as.matrix(cbind(Controls,states_dummies[,2:48],year_dummies[,2:13],Interactions,Interactions2,Interactions3[,2:48],Interactions4[,2:48]))
X = scale(X)
X = X[,-71]
confint(lm(Y_V~D_V+XO))[2,]
confint(lm(Y_P~D_P+XO))[2,]
confint(lm(Y_M~D_M+XO))[2,]
CE_V_OLS = confint(lm(Y_V~D_V+X))[2,]; CE_V_OLS
CE_P_OLS = confint(lm(Y_P~D_P+X))[2,]; CE_P_OLS
CE_M_OLS = confint(lm(Y_M~D_M+X))[2,]; CE_M_OLS
CE_V_OLSsmallmodel = confint(lm(Y_V~D_V+XO))[2,]
## lasso-based selection (naive - large model)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the model!
fit_reg = cv.glmnet(x=cbind(Dmod,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_naive = confint(causal_effect,level = 0.95)
## lasso-based selection (the right way! - large model)
library(glmnet)
boot = do(100)*{
rowindices = 1:nrow(X)
iixx = sample(rowindices,size=length(rowindices),replace=TRUE)
Xmod = X[iixx,]; Dmod = D_P[iixx]; Ymod = Y_V[iixx]
# fitting the treatment model
fit_D = cv.glmnet(x=Xmod,y=Dmod,family="gaussian",alpha=0,nlambda=20)
Dhat = predict(fit_D,newx=Xmod,s="lambda.1se")
# fitting the outcome model
fit_reg = cv.glmnet(x=cbind(Dmod-Dhat,Xmod),y=Ymod,family="gaussian",alpha=0,penalty.factor	=c(0,rep(1,ncol(Xmod))),nlambda=20)
as.numeric(coef(fit_reg,s="lambda.1se")[2])
}
causal_effect = unlist(boot)
hist(causal_effect)
CE_V_best = confint(causal_effect,level = 0.95)
# plot to visualize
yval = c(1,1,2,2,3,3,4,4)
xval = unlist(c(CE_V_OLSsmallmodel,CE_V_OLS,CE_V_naive,CE_V_best))
plot(xval,yval,col='white',bty='n',xlab='causal effect',main='Causal effect of abortion rate on violent crime')
legend('topleft',legend=c('OLS-small','OLS-large','Reg-naive','Reg-best'),col=c('red','blue','orange','green'),lwd=4)
plot(xval,yval,col='white',bty='n',xlab='causal effect',main='Causal effect of abortion rate on violent crime')
legend('topleft',legend=c('OLS-small','OLS-large','Reg-naive','Reg-best'),col=c('red','blue','orange','green'),lwd=4)
abline(v=0,lty=2)
lines(xval[1:2],yval[1:2],lwd=10,col='red')
lines(xval[3:4],yval[3:4],lwd=10,col='blue')
lines(xval[5:6],yval[5:6],lwd=10,col='orange')
lines(xval[7:8],yval[7:8],lwd=10,col='green')
library(tidyverse)
library(igraph)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
# Adapted from code by Matt Taddy
# Read in playlists from users
# This is in "long" format -- every row is a single artist-listener pair
playlists_raw = read.csv("../data/playlists.csv")
str(playlists_raw)
summary(playlists_raw)
# Turn user into a factor
playlists_raw$user = factor(playlists_raw$user)
# First create a list of baskets: vectors of items by consumer
# Analagous to bags of words
# apriori algorithm expects a list of baskets in a special format
# In this case, one "basket" of songs per user
# First split data into a list of artists for each user
playlists = split(x=playlists_raw$artist, f=playlists_raw$user)
## Remove duplicates ("de-dupe")
playlists = lapply(playlists, unique)
## Cast this variable as a special arules "transactions" class.
playtrans = as(playlists, "transactions")
summary(playtrans)
# Now run the 'apriori' algorithm
# Look at rules with support > .005 & confidence >.1 & length (# artists) <= 4
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=4))
# Look at the output... so many rules!
inspect(musicrules)
## Choose a subset
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=confidence > 0.6))
inspect(subset(musicrules, subset=lift > 10 & confidence > 0.5))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(musicrules)
library(tidyverse)
library(igraph)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
# Adapted from code by Matt Taddy
# Read in playlists from users
# This is in "long" format -- every row is a single artist-listener pair
playlists_raw = read.csv("../data/playlists.csv")
str(playlists_raw)
summary(playlists_raw)
# Turn user into a factor
playlists_raw$user = factor(playlists_raw$user)
# First create a list of baskets: vectors of items by consumer
# Analagous to bags of words
# apriori algorithm expects a list of baskets in a special format
# In this case, one "basket" of songs per user
# First split data into a list of artists for each user
playlists = split(x=playlists_raw$artist, f=playlists_raw$user)
## Remove duplicates ("de-dupe")
playlists = lapply(playlists, unique)
## Cast this variable as a special arules "transactions" class.
playtrans = as(playlists, "transactions")
summary(playtrans)
# Now run the 'apriori' algorithm
# Look at rules with support > .005 & confidence >.1 & length (# artists) <= 4
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=4))
# Look at the output... so many rules!
inspect(musicrules)
## Choose a subset
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=confidence > 0.6))
inspect(subset(musicrules, subset=lift > 10 & confidence > 0.5))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(musicrules)
dev.off()
# "two key" plot: coloring is by size (order) of item set
plot(musicrules, method='two-key plot')
# can now look at subsets driven by the plot
inspect(subset(musicrules, support > 0.035))
dev.off()
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
setwd("~/Dropbox/Charles/HeartData")
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
# making new outcome
## combine Ischemic.symptoms with "preop variables"
## single binary if any are 1, 0 otherwise.
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos") + as.numeric(DF$Preop_Perfusion_Imaging..0..CMR.or.both.neg..1..pos..2..not.done.=="Pos")
Y = Y1>0
# removing variables with no variation
iremove = which(sapply((lapply(DF,unique)),length)==1)
DF=DF[,-iremove]
gender=one_hot(as.data.table(DF$Gender))[,2]
race=one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
gender
race
fit = glmnet(x=cbind(race,gender,DF$IM.length),y=Y,family="binomial")
dim(fit$beta)
plot(fit)
Y1>0
Y = Y1>0
mean(Y)
?glmnety
?glmnet
fit = glmnet(x=cbind(race,gender,DF$IM.length),y=Y,family="binomial",alpha=1)
dim(fit$beta)
plot(fit)
fit = glmnet(x=cbind(race,gender,DF$IM.length),y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
DF$Preop_Perfusion_Imaging..0..CMR.or.both.neg..1..pos..2..not.done.
iremove
fitlogit = glm(Y~race+gender+DF$IM.length,family = "binomial")
gender=one_hot(as.data.table(DF$Gender))[,2]
race=one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
race
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
X = cbind(race,gender,DF$IM.length)
fitlogit = glm(Y~X,family = "binomial")
X
X = as.matrix(cbind(race,gender,DF$IM.length))
X
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
head(X)
fit = glmnet(x=cbind(race,gender,DF$IM.length),y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
mean(Y1)
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
mean(Y)
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos") + as.numeric(DF$Preop_Perfusion_Imaging..0..CMR.or.both.neg..1..pos..2..not.done.=="Pos")
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
mean(Y)
imlength=as.numeric(DF$IM.length)
View(DF)
one_hot(as.data.table(DF$Gender))
one_hot(as.data.table(DF$Gender))[,2]
unique(DF$Coroanry.dominance)
one_hot(as.data.table(DF$Coroanry.dominance))[,-4]
one_hot(as.data.table(DF$Coroanry.dominance))
unique(DF$Coroanry.dominance)
table1(DF$Coroanry.dominance)
table(DF$Coroanry.dominance)
table(DF$Coroanry.dominance)/sum(table(DF$Coroanry.dominance))
round(table(DF$Coroanry.dominance)/sum(table(DF$Coroanry.dominance)),2)
DF$Stenotic.ostium
cbind(DF$IM.length,DF$Length.of.IM)
intramurality = one_hot(as.data.table(DF$Intramurality))[,-1]
acuteangulation = one_hot(as.data.table(DF$Acute.angulation.))[,-1]
acuteangulation
as.data.table(DF$Acute.angulation.)
unique(DF$Acute.angulation.)
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
X = as.matrix(cbind(race,gender,imlength,cordom,ostium,geometry,intramurality,acuteangulation))
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
# making new outcome
## combine Ischemic.symptoms with "preop variables"
## single binary if any are 1, 0 otherwise.
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
# removing variables with no variation
iremove = which(sapply((lapply(DF,unique)),length)==1)
DF=DF[,-iremove]
gender = one_hot(as.data.table(DF$Gender))[,2]
race = one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
imlength = as.numeric(DF$IM.length)
cordom = one_hot(as.data.table(DF$Coroanry.dominance))[,-1]
ostium = one_hot(as.data.table(DF$Stenotic.ostium))[,-1]
geometry = one_hot(as.data.table(DF$round.oval.slit.like))[,-1]
intramurality = one_hot(as.data.table(DF$Intramurality))[,-1]
acuteangulation = one_hot(as.data.table(DF$Acute.angulation.))[,-1]
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
X = as.matrix(cbind(race,gender,imlength,cordom,ostium,geometry,intramurality,acuteangulation))
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=1)
dim(fit$beta)
plot(fit)
install.packages("plotmo")
library(plotmo)
plot_glmnet(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
?glmnet
fit = glmnet(x=X,y=Y,family="binomial",alpha=1)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
head(X)
intramurality
?one_hot
gsub(colnames(intramurality))
colnames(intramurality)
gsub("V1_","intra","V1_Yes")
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
gsub("V1_","intra",c("V1_Yes","V1_Yes"))
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
colnames(variable) = newgsub(colnames(variable,newvarname))
}
namefun(intramurality,"intramurality")
# naming function
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
colnames(variable) = newgsub(colnames(variable,newvarname))
}
namefun(intramurality,"intramurality")
# naming function
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
colnames(variable) = newgsub(colnames(variable),newvarname)
}
namefun(intramurality,"intramurality")
intramurality
variable = intramurality
newvarname= test
newvarname= "test"
colnames(variable)
newvarname
newgsub(colnames(variable),newvarname)
# naming function
newgsub = function(text,newvarname){
gsub("V1_",newvarname,text)
}
namefun = function(variable,newvarname){
newgsub(colnames(variable),newvarname)
}
colnames(intramurality)=namefun(intramurality,"intramur")
colnames(intramurality)
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
library(plotmo)
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
# making new outcome
## combine Ischemic.symptoms with "preop variables"
## single binary if any are 1, 0 otherwise.
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
# removing variables with no variation
iremove = which(sapply((lapply(DF,unique)),length)==1)
DF=DF[,-iremove]
gender = one_hot(as.data.table(DF$Gender))[,2]
colnames(gender)=namefun(gender,"gender")
race = one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
colnames(race)=namefun(race,"race")
colnames(race)
library(glmnet)
library(dummy)
library(mltools)
library(data.table)
library(plotmo)
# data
DF = as.data.frame(read.csv("R-AAOCA_new.csv"))
DF <- as.data.frame(unclass(DF),stringsAsFactors=TRUE)
str(DF)
# making new outcome
## combine Ischemic.symptoms with "preop variables"
## single binary if any are 1, 0 otherwise.
Y1 = DF$Ischemic.symptoms + as.numeric(DF$PreOp_EST.N.neg.P.pos.=="P") + as.numeric(DF$Preop_SPI=="Pos")
# removing variables with no variation
iremove = which(sapply((lapply(DF,unique)),length)==1)
DF=DF[,-iremove]
gender = one_hot(as.data.table(DF$Gender))[,2]
colnames(gender)=namefun(gender,"gender")
race = one_hot(as.data.table(DF$Race_EthnIcity))[,-4]
colnames(race)=namefun(race,"race")
imlength = as.numeric(DF$IM.length)
cordom = one_hot(as.data.table(DF$Coroanry.dominance))[,-1]
colnames(cordom)=namefun(cordom,"cordom")
ostium = one_hot(as.data.table(DF$Stenotic.ostium))[,-1]
colnames(ostium)=namefun(ostium,"ostium")
geometry = one_hot(as.data.table(DF$round.oval.slit.like))[,-1]
colnames(geometry)=namefun(geometry,"geometry")
intramurality = one_hot(as.data.table(DF$Intramurality))[,-1]
colnames(intramurality)=namefun(intramurality,"intramurality")
acuteangulation = one_hot(as.data.table(DF$Acute.angulation.))[,-1]
colnames(acuteangulation)=namefun(acuteangulation,"acuteangulation")
# building the outcome and features
Y = Y1>0 # patient, based on the tests, is "high risk" for a heart attack etc
X = as.matrix(cbind(race,gender,imlength,cordom,ostium,geometry,intramurality,acuteangulation))
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
as.matrix(cbind(race,gender,imlength,cordom,ostium,geometry,intramurality,acuteangulation))
fit = glmnet(x=X,y=Y,family="binomial",alpha=1)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
colnames(X)
X[,20]
sum(X[,20])
fit = glmnet(x=X,y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=0.5)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=0)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
fit = glmnet(x=X,y=Y,family="binomial",alpha=1)
dim(fit$beta)
plot(fit)
plot_glmnet(fit)
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
fitlogit = glm(Y~scale(X),family = "binomial")
summary(fitlogit)
fitlogit = glm(Y~scale(X,center=F),family = "binomial")
summary(fitlogit)
fitlogit = glm(Y~scale(X,scale = F),family = "binomial")
fitlogit = glm(Y~X,family = "binomial")
summary(fitlogit)
t=5
x = matrix(rnorm(10*10000,1.10,0.2),10,10000)
FV = function(PV,PMT,k,m,sd){
FV = PV
ret = rnorm(k,1+m/100,sd/100)
for(i in 1:k) FV = FV*ret[i] + PMT
return(FV)
}
M = 10000
k = 5
PV = 3
PMT = 0.15
m=10
sd=20
rr=5
tot = NULL
for(i in 1:M) tot = c(tot,FV(PV,PMT,k,m,sd))
tot = tot + (2*(1+rr/100)^k) - 0.8/(1.05)^k
sum(tot>10)/M
hist(tot)
prob = rep(0,30)
M = 10000
PV = 3
PMT = 0.15
m=10
sd=20
rr = 5
for(j in 1:30){
tot = NULL
for(i in 1:M) tot = c(tot,FV(PV,PMT,j,m,sd))
tot = tot + (2*(1+rr/100)^j) - 0.8/(1.05)^j
prob[j] = sum(tot>10)/M
}
plot(prob)
prob
dev.off()
setwd("~/Dropbox/SalemCenter/classes/PRL/Fall2023/Policy-Research-Laboratory/code")
ls()
sum(1:3)
install.packages("glmnet")
install.packages("glmnet")
library(glmnet)
